### Efficient and Self-Recoverable Privacy-Preserving k-NN (Reproduction)

This repository is a reproduction of the paper: “Efficient and self-recoverable privacy-preserving k-NN classification system with robustness to network delay.” published in Journal of Systems Architecture, 2024. [1]

The system implements a two-cloud privacy-preserving k-nearest neighbors (k-NN) classification protocol with end-to-end offline/online phases, including key generation (trusted third party), data owner encryption, two-server preprocessing and online inference, and a client that interacts with both servers to obtain the final classification.

### Repository layout

- `kNN_PKI`: Trusted third party. Generates Paillier-related keys and protocol parameters into `KeyFilePath.data`.
- `kNN_Client`: Data owner. Encrypts and packages the training database into `DO_HSS_Input_Data.data`, and prepares query files `client_query_*.data`.
- `KNN_Server`: Two identical server processes (server A and server B). Each performs offline preprocessing and then serves online queries over TCP.
- `User`: Online client. Reads the query files, interacts with both servers, performs the final k-selection and label recovery, and prints the predicted class.

### Requirements

- **OS**: Linux (recommended). The code uses POSIX sockets (`unistd.h`, `arpa/inet.h`) and `pthread`. For Windows users, use WSL2 or a Linux VM.
- **Toolchain**: CMake ≥ 3.16, GCC/G++ with C++14 or later.
- **Libraries**: GMP (`libgmp-dev`) with C++ bindings.

Install on Ubuntu 20.04:
```bash
sudo apt-get update
sudo apt-get install -y build-essential cmake libgmp-dev
```

Optional (network emulation for delay/loss, Linux only):
```bash
# Clear any existing rules
sudo tc qdisc del dev lo root || true
# Add delay
sudo tc qdisc add dev lo root netem delay 10ms
# (Optional) add loss/reorder
# sudo tc qdisc change dev lo root netem delay 10ms loss 0.1% reorder 25% 50%
```

### Build

Each subproject builds independently.

```bash
# 1) PKI
cd kNN_PKI
cmake -S . -B build
cmake --build build -j

# 2) Client (Data Owner)
cd ../kNN_Client
cmake -S . -B build
cmake --build build -j

# 3) Server
cd ../KNN_Server
cmake -S . -B build
cmake --build build -j

# 4) User (Online client)
cd ../User
cmake -S . -B build
cmake --build build -j
```

Executables are placed under each subproject’s `build/` directory (or your configured build dir).

### Default parameters

Change dataset size and k-NN settings by editing these headers (defaults shown):
- `KNN_Server/src/crypto.h`
- `kNN_Client/src/crypto.h`
- `User/crypto.h`

Key constants:
- `train_number = 115`
- `test_number = 35` (number of queries pre-generated by the data owner)
- `k_value = 5`
- `attribute_number = 5` (for Iris: 4 features + 1 label encoding)

Paillier key size defaults to 1024 bits.

### Datasets

- For Iris demo, ensure an `iris.csv` file is available in the `kNN_Client` run directory (the code expects this name by default).
- The repository also contains MNIST idx files under `*/Datasets/`, but the current default run path uses `iris.csv`.

Iris label mapping in the client:
- 0 → setosa
- 100 → versicolor
- 200 → virginica

### End-to-end workflow

Run steps must be performed in order, as files produced in earlier steps are consumed later. Paths below assume running from each subproject’s `build/` directory.

1) **Key generation (Trusted third party)**
- Working dir: `kNN_PKI/build`
- Output: `KeyFilePath.data`
```bash
./kNN_PKI
```

2) **Distribute keys**
- Copy `KeyFilePath.data` to:
  - `kNN_Client/build/`
  - `KNN_Server/build/`
```bash
cp kNN_PKI/build/KeyFilePath.data kNN_Client/build/
cp kNN_PKI/build/KeyFilePath.data KNN_Server/build/
```

3) **Data owner encryption and query preparation**
- Working dir: `kNN_Client/build`
- Inputs: `KeyFilePath.data`, `iris.csv`
- Outputs:
  - `DO_HSS_Input_Data.data` (encrypted training database for servers)
  - `client_query_0.data ... client_query_(test_number-1).data` (online queries)
```bash
./kNN_Client
```

4) **Distribute encrypted training data to servers**
- Copy `DO_HSS_Input_Data.data` to the server run directory (both servers read the same file in the same working dir):
```bash
cp kNN_Client/build/DO_HSS_Input_Data.data KNN_Server/build/
```

5) **Start the two servers (two terminals)**
- Working dir: `KNN_Server/build`
- Syntax: `./KNN_Server <server_id:1|2> <base_port> [address]`
  - Server A listens on `<base_port>`, server B on `<base_port>+1` (both bind to 127.0.0.1)
```bash
# Terminal 1
./KNN_Server 1 10086
# Terminal 2
./KNN_Server 2 10086
```

6) **Start the user client**
- Working dir: `User/build`
- Syntax: `./User <serverA_port> <serverB_port>`
- Behavior:
  - Reads `client_query_*.data` from the current directory of the data owner phase (the client program encodes and writes queries; for the default flow the last prepared query is sent).
  - Connects to both servers, receives comparison trees, performs k-selection, runs oblivious transfer, and prints the predicted label.
```bash
./User 10086 10087
```

On success, you will see logs for:
- Receiving comparison data from both servers
- Selected top-k indices
- OT results and “Predict label: ...” with Iris class name

### File handoff summary

- **From `kNN_PKI` to others**:
  - `KeyFilePath.data` → required by `kNN_Client` and `KNN_Server`
- **From `kNN_Client` to `KNN_Server`**:
  - `DO_HSS_Input_Data.data` → servers’ offline preprocessing input
- **From `kNN_Client` to `User` (online phase)**:
  - `client_query_*.data` → user packs as query strings to both servers
- **From `KNN_Server` to `User` (online phase)**:
  - `Compare_tree_0.data`, `Compare_tree_1.data` → sent over TCP and also written locally

All file paths are relative to each process’s working directory. Place/copy files into the corresponding `build/` directories where you run executables.

### Configuration tips

- **Ports**: Change when launching servers and user. By default, both servers bind to `127.0.0.1` at `<base_port>` and `<base_port>+1`.
- **Dataset/parameters**:
  - To switch datasets or dimensions, update `attribute_number`, `train_number`, etc., and ensure your CSV matches. By default Iris is expected as 4 features + label encoding.
- **Performance/networking**:
  - You can emulate delay/loss via `tc` on Linux loopback as shown above to test robustness to network conditions (see `实验步骤.md`).

### Troubleshooting

- **Missing GMP headers/libs**: install `libgmp-dev` and rebuild.
- **“Unable to read!” while servers start**: ensure `DO_HSS_Input_Data.data` is present in the server run directory and matches current key parameters.
- **“Unable to read!” in user**: ensure `client_query_*.data` exist in the user run context or adjust paths accordingly.
- **Port conflicts**: choose a different `<base_port>`.
- **Windows**: use WSL2 or a Linux environment; native Windows builds will fail due to POSIX socket and `pthread` usage.

### Acknowledgements

This code reproduces the system proposed in the provided paper “Efficient and self-recoverable privacy-preserving k-NN classification system with robustness to network delay,” implementing the full key setup, encryption, two-cloud preprocessing, and online classification flow.

- Built with GMP big-integer arithmetic (`gmp`, `gmpxx`).
- Multi-threading via `pthread`.

### Citation

@article{zhang2024efficient,
  title={Efficient and self-recoverable privacy-preserving k-NN classification system with robustness to network delay},
  author={Zhang, Jinhai and Zhang, Junwei and Ma, Zhuo and Liu, Yang and Ma, Xindi and Ma, Jianfeng},
  journal={Journal of Systems Architecture},
  volume={150},
  pages={103111},
  year={2024},
  publisher={Elsevier}
}

[1] Zhang J, Zhang J, Ma Z, et al. Efficient and self-recoverable privacy-preserving k-NN classification system with robustness to network delay[J]. Journal of Systems Architecture, 2024, 150: 103111.

